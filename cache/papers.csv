type,category,title,authors,url,journal,vol,num,pages,date,first_date,publisher,abstract,notes,materials
publication,Statistical methodology,Estimating racial disparities when race is not observed,"McCartan, Cory; Fisher, Robin; Goldin, Jacob; Ho, Daniel E.; Imai, Kosuke;",https://doi.org/10.1080/01621459.2025.2526695,Journal of the American Statistical Association,NA,NA,Forthcoming,2025,2022,American Statistical Association,"The estimation of racial disparities in various fields is often hampered by the lack of individual-level racial information. In many cases, the law prohibits the collection of such information to prevent direct racial discrimination. As a result, analysts have frequently adopted Bayesian Improved Surname Geocoding (BISG) and its variants, which combine individual names and addresses with Census data to predict race. Unfortunately, the residuals of BISG are often correlated with the outcomes of interest, generally attenuating estimates of racial disparities. To correct this bias, we propose an alternative identification strategy under the assumption that surname is conditionally independent of the outcome given (unobserved) race, residence location, and other observed characteristics. We introduce a new class of models, Bayesian Instrumental Regression for Disparity Estimation (BIRDiE), that take BISG probabilities as inputs and produce racial disparity estimates by using surnames as an instrumental variable for race. Our estimation method is scalable, making it possible to analyze large-scale administrative data. We also show how to address potential violations of the key identification assumptions. A validation study based on the North Carolina voter file shows that BISG+BIRDiE reduces error by up to 84% when estimating racial differences in party registration. Finally, we apply the proposed methodology to estimate racial differences in who benefits from the home mortgage interest deduction using individual-level tax data from the U.S. Internal Revenue Service. Open-source software is available which implements the proposed methodology.",NA,"[Software](https://corymccartan.com/birdie);
[Replication code](https://github.com/CoryMcCartan/birdie-replication);
[Poster](/docs/poster_race.pdf)"
publication,Differential privacy and the census,Evaluating Bias and Noise Induced by the U.S. Census Bureau's Privacy Protection Methods,"Kenny, Christopher T.; McCartan, Cory; Simko, Tyler; Kuriwaki, Shiro; Imai, Kosuke;",https://doi.org/10.1126/sciadv.adl2524,Science Advances,10,18,eadl2524,2024,2023,American Association for the Advancement of Science,"The United States Census Bureau faces a difficult trade-off between the accuracy of Census statistics and the protection of individual information. We conduct the first independent evaluation of bias and noise induced by the Bureau's two main disclosure avoidance systems: the TopDown algorithm employed for the 2020 Census and the swapping algorithm implemented for the 1990, 2000, and 2010 Censuses. Our evaluation leverages the recent release of the Noisy Measure File (NMF) as well as the availability of two independent runs of the TopDown algorithm applied to the 2010 decennial Census. We find that the NMF contains too much noise to be directly useful alone, especially for Hispanic and multiracial populations. TopDown's post-processing dramatically reduces the NMF noise and produces similarly accurate data to swapping in terms of bias and noise. These patterns hold across census geographies with varying population sizes and racial diversity. While the estimated errors for both TopDown and swapping are generally no larger than other sources of Census error, they can be relatively substantial for geographies with small total populations.",NA,[Replication code](https://doi.org/10.7910/DVN/TMIN3H)
publication,Redistricting and geography,Measuring and Modeling Neighborhoods,"McCartan, Cory; Brown, Jacob R.; Imai, Kosuke;",https://doi.org/10.1017/S0003055423001429,American Political Science Review,118,4,1966-1985,2024,2021,American Political Science Association,"Granular geographic data present new opportunities to understand how neighborhoods are formed, and how they influence politics. At the same time, the inherent subjectivity of neighborhoods creates methodological challenges in measuring and modeling them. We develop an open-source survey instrument that allows respondents to draw their neighborhoods on a map. We also propose a statistical model to analyze how the characteristics of respondents and local areas determine subjective neighborhoods. We conduct two surveys: collecting subjective neighborhoods from voters in Miami, New York City, and Phoenix, and asking New York City residents to draw a community of interest for inclusion in their city council district. Our analysis shows that, holding other factors constant, White respondents include census blocks with more White residents in their neighborhoods. Similarly, Democrats and Republicans are more likely to include co-partisan areas. Furthermore, our model provides more accurate out-of-sample predictions than standard neighborhood measures.",NA,"[Survey tool](https://github.com/CoryMcCartan/neighborhood-survey);
[Replication code](https://doi.org/10.7910/DVN/SDSUQG);
[Poster](/docs/poster_nbhd.pdf)"
publication,Differential privacy and the census,Census Officials Must Constructively Engage with Independent Evaluations,"Kenny, Christopher T.; McCartan, Cory; Simko, Tyler; Imai, Kosuke;",https://doi.org/10.1073/pnas.2321196121,Proceedings of the National Academy of Sciences,121,11,e2321196121,2024,2023,National Academy of Sciences,NA,Letter to the editor re: [Jarmin et al. (2023)](https://doi.org/10.1073/pnas.2220558120).,NA
publication,Differential privacy and the census,Making Differential Privacy Work for Census Data Users,"McCartan, Cory; Simko, Tyler; Imai, Kosuke;",https://doi.org/10.1162/99608f92.c3c87223,Harvard Data Science Review,5,4,NA,2023,2023,MIT Press,"The U.S. Census Bureau collects and publishes detailed demographic data about Americans which are heavily used by researchers and policymakers. The Bureau has recently adopted the framework of differential privacy in an effort to improve confidentiality of individual census responses. A key output of this privacy protection system is the Noisy Measurement File (NMF), which is produced by adding random noise to tabulated statistics. The NMF is critical to understanding any biases in the data, and performing valid statistical inference on published census data. Unfortunately, the current release format of the NMF is difficult to access and work with. We describe the process we use to transform the NMF into a usable format, and provide recommendations to the Bureau for how to release future versions of the NMF. These changes are essential for ensuring transparency of privacy measures and reproducibility of scientific research built on census data.",With [response](https://doi.org/10.1162/99608f92.79d4660d) and [rejoinder](https://doi.org/10.1162/99608f92.f9f4b9a4).,NA
publication,Redistricting and geography,Sequential Monte Carlo for sampling balanced and compact redistricting plans,"McCartan, Cory; Imai, Kosuke;",https://doi.org/10.1214/23-AOAS1763,Annals of Applied Statistics,17,4,3300-3323,2023,2020,Institute of Mathematical Statistics,"Random sampling of graph partitions under constraints has become a popular tool for evaluating legislative redistricting plans. Analysts detect partisan gerrymandering by comparing a proposed redistricting plan with an ensemble of sampled alternative plans. For successful application, sampling methods must scale to large maps with many districts, incorporate realistic legal constraints, and accurately and efficiently sample from a selected target distribution. Unfortunately, most existing methods struggle in at least one of these areas. We present a new Sequential Monte Carlo (SMC) algorithm that generates a sample of redistricting plans converging to a realistic target distribution. Because it draws many plans in parallel, the SMC algorithm can efficiently explore the relevant space of redistricting plans better than the existing Markov chain Monte Carlo (MCMC) algorithms that generate plans sequentially. Our algorithm can simultaneously incorporate several constraints commonly imposed in real-world redistricting problems, including equal population, compactness, and preservation of administrative boundaries. We validate the accuracy of the proposed algorithm by using a small map where all redistricting plans can be enumerated. We then apply the SMC algorithm to evaluate the partisan implications of several maps submitted by relevant parties in a recent high-profile redistricting case in the state of Pennsylvania. We find that the proposed algorithm converges to the target distribution faster and with fewer samples than a state-of-the-art MCMC algorithm. Open-source software is available for implementing the proposed methodology.","Covered by [*The Washington Post*](https://www.washingtonpost.com/politics/interactive/2022/algorithmic-redistricting/), [*Quanta* magazine](https://www.quantamagazine.org/how-math-has-changed-the-shape-of-gerrymandering-20230601/).",[Software](https://alarm-redist.org/redist/)
publication,Redistricting and geography,"Widespread partisan gerrymandering mostly cancels nationally, but reduces electoral competition","Kenny, Christopher T.; McCartan, Cory; Simko, Tyler; Kuriwaki, Shiro; Imai, Kosuke;",https://doi.org/10.1073/pnas.2217322120,Proceedings of the National Academy of Sciences,120,25,e2217322120,2023,2022,National Academy of Sciences,"Congressional district lines in many U.S. states are drawn by partisan actors, raising concerns about gerrymandering. To isolate the electoral impact of gerrymandering from the effects of other factors including geography and redistricting rules, we compare predicted election outcomes under the enacted plan with those under a large sample of non-partisan, simulated alternative plans for all states. We find that partisan gerrymandering is widespread in the 2020 redistricting cycle, but most of the bias it creates cancels at the national level, giving Republicans two additional seats, on average. In contrast, moderate pro-Republican bias due to geography and redistricting rules remains. Finally, we find that partisan gerrymandering reduces electoral competition and makes the House's partisan composition less responsive to shifts in the national vote.",NA,[Replication code](https://doi.org/10.7910/DVN/JI1U8X)
publication,Differential privacy and the census,Researchers need better access to U.S. Census data,"McCartan, Cory; Simko, Tyler; Imai, Kosuke;",https://doi.org/10.1126/science.adi7004,Science,380,6648,902-903,2023,2023,American Association for the Advancement of Science,NA,NA,NA
publication,Statistical methodology,"Recalibration of Predicted Probabilities Using the “Logit Shift”: Why Does It Work, and When Can It Be Expected to Work Well?","Rosenman, Evan T.R.; McCartan, Cory; Olivella, Santiago;",https://doi.org/10.1017/pan.2022.31,Political Analysis,31,4,651-661,2023,2022,Cambridge University Press,"The output of predictive models is routinely recalibrated by reconciling low-level predictions with known quantities defined at higher levels of aggregation. For example, models predicting vote probabilities at the individual level in U.S. elections can be adjusted so that their aggregation matches the observed vote totals in each county, thus producing better calibrated predictions. In this research note, we provide theoretical grounding for one of the most commonly used recalibration strategies, known colloquially as the “logit shift.” Typically cast as a heuristic adjustment strategy (whereby a constant correction on the logit scale is found, such that aggregated predictions match target totals), we show that the logit shift offers a fast and accurate approximation to a principled, but computationally impractical adjustment strategy: computing the posterior prediction probabilities, conditional on the observed totals. After deriving analytical bounds on the quality of the approximation, we illustrate its accuracy using Monte Carlo simulations. We also discuss scenarios in which the logit shift is less effective at recalibrating predictions: when the target totals are defined only for highly heterogeneous populations, and when the original predictions correctly capture the mean of true individual probabilities, but fail to capture the shape of their distribution.",NA,[Software snippet](https://gist.github.com/CoryMcCartan/220701121c3f0520c2878e0010ced26b)
publication,Differential privacy and the census,Comment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure Avoidance System,"Kenny, Christopher T.; Kuriwaki, Shiro; McCartan, Cory; Rosenman, Evan T.R.; Simko, Tyler; Imai, Kosuke;",https://doi.org/10.1162/99608f92.abc2c765,Harvard Data Science Review,NA,NA,Special Issue 2,2023,2022,MIT Press,"In ""Differential Perspectives: Epistemic Disconnects Surrounding the US Census Bureau's Use of Differential Privacy,"" boyd and Sarathy argue that empirical evaluations of the Census Disclosure Avoidance System (DAS), including our published analysis, failed to recognize how the benchmark data against which the 2020 DAS was evaluated is never a ground truth of population counts. In this commentary, we explain why policy evaluation, which was the main goal of our analysis, is still meaningful without access to a perfect ground truth. We also point out that our evaluation leveraged features specific to the decennial Census and redistricting data, such as block-level population invariance under swapping and voter file racial identification, better approximating a comparison with the ground truth. Lastly, we show that accurate statistical predictions of individual race based on the Bayesian Improved Surname Geocoding, while not a violation of differential privacy, substantially increases the disclosure risk of private information the Census Bureau sought to protect. We conclude by arguing that policy makers must confront a key trade-off between data utility and privacy protection, and an epistemic disconnect alone is insufficient to explain disagreements between policy choices.",Response to [boyd and Sarathy (2022)](https://hdsr.mitpress.mit.edu/pub/3vj5j6i0/release/1?readingCollection=a133a0a2).,NA
publication,Redistricting and geography,Simulated redistricting plans for the analysis and evaluation of redistricting in the United States,"McCartan, Cory; Kenny, Christopher T.; Simko, Tyler; Garcia III, George; Wang, Kevin; Wu, Melissa; Kuriwaki, Shiro; Imai, Kosuke;",https://doi.org/10.1038/s41597-022-01808-2,Nature: Scientific Data,9,1,689,2022,2022,Nature Publishing Group UK London,"A collection of simulated congressional districting plans and underlying code developed by the Algorithm-Assisted Redistricting Methodology (ALARM) Project. The data allow for the evaluation of enacted and other congressional redistricting plans in the United States.  While the use of redistricting simulation algorithms has become standard in academic research and court cases, any simulation analysis requires non-trivial efforts to combine multiple data sets, identify state-specific redistricting criteria, implement complex simulation algorithms, and summarize and visualize simulation outputs.  We have developed a complete workflow that facilitates this entire process of simulation-based redistricting analysis for the congressional districts of all 50 states.  The resulting data include ensembles of simulated 2020 congressional redistricting plans and necessary replication data.  We provide the underlying code, which serves as a template for customized analyses.  All data and code are free and publicly available.",Covered by [*The New York Times*](https://www.nytimes.com/interactive/2025/08/21/upshot/up-massachusetts-redistricting.html).,"[Project website](https://alarm-redist.org/fifty-states/);
[Replication code](https://github.com/alarm-redist/fifty-states);
[Data](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SLCD3E)"
publication,Differential privacy and the census,The use of differential privacy for census data and its impact on redistricting: The case of the 2020 U.S. Census,"Kenny, Christopher T.; Kuriwaki, Shiro; McCartan, Cory; Rosenman, Evan T.R.; Simko, Tyler; Imai, Kosuke;",https://doi.org/10.1126/sciadv.abk3283,Science Advances,7,41,eabk3283,2021,2021,American Association for the Advancement of Science,"Census statistics play a key role in public policy decisions and social science research. However, given the risk of revealing individual information, many statistical agencies are considering disclosure control methods based on differential privacy, which add noise to tabulated data. Unlike other applications of differential privacy, however, census statistics must be postprocessed after noise injection to be usable. We study the impact of the U.S. Census Bureau’s latest disclosure avoidance system (DAS) on a major application of census statistics, the redrawing of electoral districts. We find that the DAS systematically undercounts the population in mixed-race and mixed-partisan precincts, yielding unpredictable racial and partisan biases. While the DAS leads to a likely violation of the “One Person, One Vote” standard as currently interpreted, it does not prevent accurate predictions of an individual’s race and ethnicity. Our findings underscore the difficulty of balancing accuracy and respondent privacy in the Census.","Originally a Public Comment to the Census Bureau (May 28, 2021).

Covered by [*The Washington Post*](
https://www.washingtonpost.com/local/social-issues/2020-census-differential-privacy-ipums/2021/06/01/6c94b46e-c30d-11eb-93f5-ee9558eecf4b_story.html),
the [*Associated Press*](https://apnews.com/article/business-census-2020-technology-e701e313e841674be6396321343b7e49),
the [*San Francisco Chronicle*](https://www.sfchronicle.com/us-world/article/The-most-detailed-data-about-the-US-population-in-16378154.php),
[*NC Policy Watch*](
http://pulse.ncpolicywatch.org/2021/06/14/expert-census-bureaus-actions-to-protect-individual-privacy-could-have-big-impact-on-redistricting/), and others.","[FAQ](https://alarm-redist.org/posts/2021-06-02-das-evaluation-faq/);
[Reaction to the Bureau's Response](https://alarm-redist.org/posts/2021-06-09-dsep-decision-response/);
[Supplementary information](https://www.science.org/doi/suppl/10.1126/sciadv.abk3283/suppl_file/sciadv.abk3283_sm.pdf);
[Replication materials](https://doi.org/10.7910/DVN/TNNSXG)"
publication,Other,Geodesic interpolation on Sierpinski gaskets,"Davis, Caitlin; LeGare, Laura; McCartan, Cory; Rogers, Luke;",https://doi.org/10.4171/JFG/100,Journal of Fractal Geometry,8,2,117-152,2021,2019,European Mathematical Society,"We study the analogue of a convex interpolant of two sets on Sierpiński gaskets and an associated notion of measure transport. The structure of a natural family of interpolating measures is described and an interpolation inequality is established. A key tool is a good description of geodesics on these gaskets, some results on which have previously appeared in the literature.",NA,NA
working paper,Statistical methodology,Relative Bias Under Imperfect Identification in Observational Causal Inference,"Huang, Melody; McCartan, Cory",https://arxiv.org/abs/2507.23743,arXiv preprint,NA,NA,Under Review,2025,2025,NA,"To conduct causal inference in observational settings, researchers must rely on certain identifying assumptions. In practice, these assumptions are unlikely to hold exactly. This paper considers the bias of selection-on-observables, instrumental variables, and proximal inference estimates under violations of their identifying assumptions. We develop bias expressions for IV and proximal inference that show how violations of their respective assumptions are amplified by any unmeasured confounding in the outcome variable. We propose a set of sensitivity tools that quantify the sensitivity of different identification strategies, and an augmented bias contour plot visualizes the relationship between these strategies. We argue that the act of choosing an identification strategy implicitly expresses a belief about the degree of violations that must be present in alternative identification strategies. Even when researchers intend to conduct an IV or proximal analysis, a sensitivity analysis comparing different identification strategies can help to better understand the implications of each set of assumptions. Throughout, we compare the different approaches on a re-analysis of the impact of state surveillance on the incidence of protest in Communist Poland.",NA,NA
working paper,Redistricting and geography,Gerrymandering and geographic polarization have reduced electoral competition,"Jasny, Ethan; Kenny, Christopher T,; McCartan, Cory; Simko, Tyler; Wu, Melissa; Zhao, Michael Y.; Arora, Aneetej; Ebowe, Emma; O'Sullivan, Philip; Samarth, Taran; Imai, Kosuke",https://alarm-redist.org/papers/ggprec.pdf,preprint,NA,NA,NA,2025,2025,NA,"Changes in political geography and electoral district boundaries shape representation in the United States Congress. To disentangle the effects of geography and gerrymandering, we generate a large ensemble of alternative redistricting plans that follow each state's legal criteria. Comparing enacted plans to these simulations reveals partisan bias, while changes in the simulated plans over time identify shifts in political geography. Our analysis shows that geographic polarization has intensified between 2010 and 2020: Republicans improved their standing in rural and rural-suburban areas, while Democrats further gained in urban districts. These shifts offset nationally, reducing the Republican geographic advantage from 14 to 10 seats. Additionally, pro-Democratic gerrymandering in 2020 counteracted earlier Republican efforts, reducing the GOP redistricting advantage by two seats. In total, the pro-Republican bias declined from 16 to 10 seats. Crucially, shifts in political geography and gerrymandering reduced the number of highly competitive districts by over 25%, with geographic polarization driving most of the decline.",NA,NA
working paper,Statistical methodology,The Role of Confounders and Linearity in Ecological Inference: A Reassessment,"Kuriwaki, Shiro; McCartan, Cory",NA,preprint,NA,NA,NA,2025,2025,NA,"Estimating conditional means only with aggregate data is commonly known as the ecological inference problem (EI). We provide a reassessment of ecological inference: a formalization of the problem that differs from existing work, identification conditions, and an empirical characterization of how these conditions fail in common cases. In particular, the quantity of interest in EI is governed by a conditional expectation function, and identification requires estimating this function controlling for confounders. In this way, EI is similar to causal inference with observational data, but with aggregation contributing additional structure to assist in the estimation problem. Using this perspective, we clarify the differences between the EI methods commonly used in the literature, and explain when they lead to ecological fallacies. Illustrating with common EI problems in political science with datasets where true values are fortuitously observed, we find that methods are prone to overestimating racial polarization and underestimating ticket splitting, but covariates can help.",NA,NA
working paper,Redistricting and geography,Redistricting Reforms Reduce Gerrymandering by Constraining Partisan Actors,"McCartan, Cory; Kenny, Christopher T.; Simko, Tyler; Ebowe, Emma; Zhao, Michael Y.; Imai, Kosuke",https://arxiv.org/abs/2407.11336,arXiv preprint,NA,NA,Under Review,2024,2024,NA,"Political actors frequently manipulate redistricting plans to gain electoral advantages, a process commonly known as gerrymandering. To address this problem, several states have implemented institutional reforms including the establishment of map-drawing commissions. It is difficult to assess the impact of such reforms because each state structures bundles of complex rules in different ways. We propose to model redistricting processes as a sequential game. The equilibrium solution to the game summarizes multi-step institutional interactions as a single dimensional score. This score measures the leeway political actors have over the partisan lean of the final plan. Using a differences-in-differences design, we demonstrate that reforms reduce partisan bias and increase competitiveness when they constrain partisan actors. We perform a counterfactual policy analysis to estimate the partisan effects of enacting recent institutional reforms nationwide. We find that instituting redistricting commissions generally reduces the current Republican advantage, but Michigan-style reforms would yield a much greater pro-Democratic effect than types of redistricting commissions adopted in Ohio and New York.",NA,NA
working paper,Redistricting and geography,Individual and differential harm in redistricting,"McCartan, Cory; Kenny, Christopher T.;",https://osf.io/preprints/socarxiv/nc2x7/,SocArXiv preprint,NA,NA,Under Review,2022,2022,NA,"Social scientists have developed dozens of measures for assessing partisan bias in redistricting. But these measures cannot be easily adapted to other groups, including those defined by race, class, or geography. Nor are they applicable to single- or no-party contexts such as local redistricting. To overcome these limitations, we propose a unified framework of _harm_ for evaluating the impacts of a districting plan on individual voters and the groups to which they belong. We consider a voter harmed if their chosen candidate is not elected under the current plan, but would be under a different plan. Harm improves on existing measures by both focusing on the choices of individual voters and directly incorporating counterfactual plans. We discuss strategies for estimating harm, and demonstrate the utility of our framework through analyses of partisan gerrymandering in New Jersey, voting rights litigation in Alabama, and racial dynamics of Boston City Council elections.",NA,[Replication code](https://github.com/CoryMcCartan/harm-redistricting)
working paper,Redistricting and geography,Projective Averages for Summarizing Redistricting Ensembles,"McCartan, Cory;",https://arxiv.org/abs/2401.06381,arXiv preprint,NA,NA,NA,2024,2024,NA,"A recurring challenge in the application of redistricting simulation algorithms lies in extracting useful summaries and comparisons from a large ensemble of districting plans. Researchers often compute summary statistics for each district in a plan, and then study their distribution across the plans in the ensemble. This approach discards rich geographic information that is inherent in districting plans. We introduce the projective average, an operation that projects a district-level summary statistic back to the underlying geography and then averages this statistic across plans in the ensemble. Compared to traditional district-level summaries, projective averages are a powerful tool for geographically granular, sub-district analysis of districting plans along a variety of dimensions. However, care must be taken to account for variation within redistricting ensembles, to avoid misleading conclusions. We propose and validate a multiple-testing procedure to control the probability of incorrectly identifying outlier plans or regions when using projective averages.",NA,[Replication code](https://github.com/CoryMcCartan/proj-avg)
working paper,Redistricting and geography,Finding Pareto efficient redistricting plans with short bursts,"McCartan, Cory;",https://arxiv.org/abs/2304.00427,arXiv preprint,NA,NA,NA,2024,2023,NA,"Redistricting practitioners must balance many competing constraints and criteria when drawing district boundaries. To aid in this process, researchers have developed many methods for optimizing districting plans according to one or more criteria. This research note extends a recently-proposed single-criterion optimization method, short bursts (Cannon et al., 2023), to handle the multi-criterion case, and in doing so approximate the Pareto frontier for any set of constraints. We study the empirical performance of the method in a realistic setting and find it behaves as expected and is not very sensitive to algorithmic parameters. The proposed approach, which is implemented in open-source software, should allow researchers and practitioners to better understand the tradeoffs inherent to the redistricting process. </p>",NA,[Replication code](https://github.com/CoryMcCartan/redist-pareto)
other,NA,Candy cane shortages and the importance of variation,"McCartan, Cory;",https://isi-web.org/article/candy-cane-shortages-and-importance-variation,Statisticians React to the News,NA,NA,NA,"December 21, 2021",NA,International Statistical Institute,NA,NA,NA
other,NA,Where will the rocket land?,"McCartan, Cory;",https://isi-web.org/article/where-will-rocket-land,Statisticians React to the News,NA,NA,NA,"May 12, 2021",NA,International Statistical Institute,NA,NA,NA
other,NA,"Who’s the most electable Democrat? It might be Warren or Buttigieg, not Biden","McCartan, Cory;",https://www.washingtonpost.com/politics/2019/10/23/whos-most-electable-democrat-it-might-be-warren-or-buttigieg-not-biden/,The Washington Post,NA,NA,NA,"October 23, 2019",NA,NA,NA,NA,NA
other,NA,"I-405 Express Toll Lanes: Usage, benefits, and equity","Leung, Shirley; McCartan, Cory; Robinson, C.J.; Roshan Zamir, Kiana; Iverson, Vaughn; Hallenbeck, Mark;",https://www.wsdot.wa.gov/publications/fulltext/design/ConsultantSrvs/I-405ExpressTollLanes.pdf,NA,NA,NA,NA,2019,NA,Technical report for the Washington State Department of Transportation,"Congestion is increasing in cities around the country, and particularly in the Seattle region. Local governments are increasingly experimenting with congestion pricing schemes to manage congestion. The Washington State Department of Transportation (WSDOT) opened a congestion pricing facility in 2015 on I-405, which runs through the eastern suburbs of Seattle. The facility operates by selling extra space in the high-occupancy vehicle (HOV) lanes to single-occupancy vehicles (SOVs), and dynamically changing the price of entry to manage demand and keep the lanes operating. These combined HOV and tolled SOV lanes are called High Occupancy Tolling (HOT) lanes.

While the HOT lanes have been operative for over three years, there has been little research into the equity impacts of the lanes. Using data on each trip made on the I-405 HOT lanes in 2018, demographic data on census block groups, and lane speed, volume, and travel time data, we tried to answer this question. We studied how the express toll lanes are used, the benefits they provide to the region, and how these benefits are distributed among different groups of users.",NA,[Project website](https://uwescience.github.io/hot-lane-equity/)
